{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Image with Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download some realife images.\n",
    "\n",
    "Like this [6gb coco data](http://images.cocodataset.org/zips/val2014.zip)\n",
    "\n",
    "Or this [19gb coco data](http://images.cocodataset.org/zips/unlabeled2017.zip) will work even better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A spacialized dataset for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "class super_res(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        A dataset to spit out low and high version of the same picture\n",
    "        root_dir: directory of the images\n",
    "        \n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir if root_dir[-1]==\"/\" else root_dir+\"/\"\n",
    "        \n",
    "        self.resize1 = transforms.Resize((128,128)) # function: resize to smaller\n",
    "        self.resize2 = transforms.Resize((256,256)) # function: resize to bigger\n",
    "        \n",
    "        self.data_aug = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(), # function flip\n",
    "            transforms.RandomAffine(5), # function rotate\n",
    "                              ])\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        self.imgs = glob(self.root_dir + \"*.jpg\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        img = Image.open(img_name,mode = \"r\").convert('RGB')\n",
    "        image_l = self.toTensor(self.resize1(self.data_aug(img))) # Low resolution version\n",
    "        image_h = self.toTensor(self.resize2(self.data_aug(img))) # High resolution version\n",
    "\n",
    "        return image_l, image_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "CUDA = cuda.is_available()\n",
    "DATA = \"/data/unlabeled2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.2863,  0.0039,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.3137,  0.0078,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.3020,  0.0078,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0039,  0.1255,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0039,  0.1412,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0039,  0.1216,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.3176,  0.0039,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.3529,  0.0078,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.3451,  0.0078,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0039,  0.1412,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0039,  0.1529,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0039,  0.1294,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.3529,  0.0078,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.3922,  0.0118,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.3922,  0.0078,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0039,  0.1490,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0039,  0.1490,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0039,  0.1216,  ...,  0.0000,  0.0000,  0.0000]]]]),\n",
       " tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.5216,  0.4510,  0.0667],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.5059,  0.4353,  0.0667],\n",
       "           [ 0.0118,  0.0118,  0.0118,  ...,  0.5020,  0.4314,  0.0627],\n",
       "           ...,\n",
       "           [ 0.0196,  0.1137,  0.1098,  ...,  0.0078,  0.0078,  0.0078],\n",
       "           [ 0.0196,  0.1294,  0.1451,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0235,  0.1922,  0.2314,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.5451,  0.4706,  0.0706],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.5294,  0.4549,  0.0706],\n",
       "           [ 0.0118,  0.0118,  0.0118,  ...,  0.5216,  0.4510,  0.0667],\n",
       "           ...,\n",
       "           [ 0.0196,  0.1294,  0.1255,  ...,  0.0078,  0.0078,  0.0078],\n",
       "           [ 0.0235,  0.1451,  0.1647,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0275,  0.2078,  0.2510,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.6078,  0.5255,  0.0784],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.5961,  0.5137,  0.0784],\n",
       "           [ 0.0157,  0.0157,  0.0157,  ...,  0.5961,  0.5137,  0.0784],\n",
       "           ...,\n",
       "           [ 0.0196,  0.1294,  0.1137,  ...,  0.0078,  0.0078,  0.0078],\n",
       "           [ 0.0235,  0.1529,  0.1686,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0314,  0.2275,  0.2706,  ...,  0.0000,  0.0000,  0.0000]]]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = super_res(DATA)\n",
    "dl = DataLoader(ds,batch_size=1,shuffle = True)\n",
    "generator = iter(dl)\n",
    "next(generator)\n",
    "# len(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_,out_,ks, stride,activation = True):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_,out_,kernel_size = ks, stride = stride, padding = ks//2, bias = False),\n",
    "        nn.BatchNorm2d(out_),\n",
    "    ]\n",
    "    if activation: layers.append(nn.LeakyReLU())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(3,4,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class res_block(nn.Module):\n",
    "    def __init__(self,nb_filter):\n",
    "        \"\"\"\n",
    "        simple resnet block\n",
    "        \"\"\"\n",
    "        super(res_block,self).__init__()\n",
    "        self.nb_filter = nb_filter\n",
    "        self.clayer1 = conv_layer(self.nb_filter,self.nb_filter,3,(1,1))\n",
    "        self.clayer2 = conv_layer(self.nb_filter,self.nb_filter,3,(1,1),activation = False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x2 = self.clayer2(self.clayer1(x))\n",
    "        return x2+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block(nb_filters):\n",
    "    layers = [nn.Upsample(scale_factor=2),\n",
    "                conv_layer(nb_filters,nb_filters,3,stride = (1,1),activation=True),\n",
    "             ]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small2big(nn.Module):\n",
    "    def __init__(self,nb_filters=64):\n",
    "        super(small2big,self).__init__()\n",
    "        self.nb_filters = nb_filters\n",
    "        self.input_conv = conv_layer(in_=3,out_=self.nb_filters,ks=9,stride=1)\n",
    "        self.res_blocks = nn.Sequential(*list(res_block(self.nb_filters) for i in range(6)))\n",
    "        self.up = nn.Sequential(*list(up_block(self.nb_filters) for i in range(1)))\n",
    "        self.output_conv = nn.Sequential(*[\n",
    "            nn.Conv2d(in_channels=self.nb_filters,out_channels=3,kernel_size=3,stride=(1,1),padding = 1),\n",
    "            nn.Sigmoid(),\n",
    "                                          ])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_conv(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.up(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_res_model = small2big()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Scale and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_res_model(torch.rand(2,3,128,128)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA:\n",
    "    super_res_model = super_res_model.cuda()\n",
    "from torch.optim import Adam\n",
    "loss_func = nn.MSELoss()\n",
    "opt = Adam(super_res_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.matchbox import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    \"\"\"\n",
    "    model:pytorch model\n",
    "    path:save to path, end with pkl\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model,path):\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(*args,**kwargs):\n",
    "    low,high = args[0]\n",
    "    if CUDA:\n",
    "        low,high = low.cuda(),high.cuda()\n",
    "    opt.zero_grad()\n",
    "    high_ = super_res_model(low)\n",
    "    \n",
    "    loss = loss_func(high_,high)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if kwargs[\"ite\"]%10==9:\n",
    "        save_model(super_res_model,\"super_res_0.0.1.npy\")\n",
    "    return {\"loss\":loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⭐[ep_0_i_69]\tloss\t0.043:   2%|▏         | 71/3857 [02:13<1:58:13,  1.87s/it]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(ds ,batch_size = 32, print_on= 5)\n",
    "trainer.action = action\n",
    "\n",
    "trainer.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
