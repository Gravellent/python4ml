{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Image with Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download some realife images.\n",
    "\n",
    "Like this [6gb coco data](http://images.cocodataset.org/zips/val2014.zip)\n",
    "\n",
    "Or this [19gb coco data](http://images.cocodataset.org/zips/unlabeled2017.zip) will work even better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A spacialized dataset for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "class super_res(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        A dataset to spit out low and high version of the same picture\n",
    "        root_dir: directory of the images\n",
    "        \n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir if root_dir[-1]==\"/\" else root_dir+\"/\"\n",
    "        \n",
    "        self.resize1 = transforms.Resize((128,128)) # function: resize to smaller\n",
    "        self.resize2 = transforms.Resize((256,256)) # function: resize to bigger\n",
    "        \n",
    "        self.data_aug = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(), # function flip\n",
    "            transforms.RandomAffine(5), # function rotate\n",
    "                              ])\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        self.imgs = glob(self.root_dir + \"*.jpg\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        img = Image.open(img_name,mode = \"r\").convert('RGB')\n",
    "        image_l = self.toTensor(self.resize1(self.data_aug(img))) # Low resolution version\n",
    "        image_h = self.toTensor(self.resize2(self.data_aug(img))) # High resolution version\n",
    "\n",
    "        return image_l, image_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/data/unlabeled2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/unlabeled2017/000000437307.jpg',\n",
       " '/data/unlabeled2017/000000227544.jpg',\n",
       " '/data/unlabeled2017/000000388209.jpg']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.imgs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.2353,  0.2667,  0.1137],\n",
       "         [ 0.0863,  0.0941,  0.1020,  ...,  0.4275,  0.4706,  0.2118],\n",
       "         [ 0.1647,  0.1804,  0.2078,  ...,  0.5412,  0.6667,  0.2863],\n",
       "         ...,\n",
       "         [ 0.3725,  0.7765,  0.8196,  ...,  0.8314,  0.8275,  0.7961],\n",
       "         [ 0.3137,  0.8118,  0.8157,  ...,  0.4118,  0.4118,  0.4157],\n",
       "         [ 0.3451,  0.7647,  0.8039,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.2471,  0.2706,  0.1137],\n",
       "         [ 0.0627,  0.0706,  0.0863,  ...,  0.4275,  0.4118,  0.1804],\n",
       "         [ 0.1294,  0.1451,  0.1686,  ...,  0.4824,  0.5804,  0.2314],\n",
       "         ...,\n",
       "         [ 0.2980,  0.6118,  0.6706,  ...,  0.6941,  0.6902,  0.6588],\n",
       "         [ 0.2588,  0.6627,  0.6667,  ...,  0.3451,  0.3451,  0.3451],\n",
       "         [ 0.2745,  0.6039,  0.6471,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.2510,  0.2667,  0.1137],\n",
       "         [ 0.0588,  0.0706,  0.0784,  ...,  0.4039,  0.3686,  0.1647],\n",
       "         [ 0.1176,  0.1373,  0.1569,  ...,  0.5333,  0.5608,  0.2118],\n",
       "         ...,\n",
       "         [ 0.2196,  0.4627,  0.4980,  ...,  0.5098,  0.5020,  0.4824],\n",
       "         [ 0.1804,  0.4941,  0.4980,  ...,  0.2510,  0.2471,  0.2471],\n",
       "         [ 0.2118,  0.4392,  0.4980,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.toTensor(ds.resize1(ds.data_aug(Image.open(ds.imgs[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0039,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0039,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0039,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0039,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0039,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0039,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]),\n",
       " tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = super_res(DATA)\n",
    "dl = DataLoader(ds,batch_size=1,shuffle = True)\n",
    "generator = iter(dl)\n",
    "next(generator)\n",
    "# len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_,out_,ks, stride,activation = True):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_,out_,kernel_size = ks, stride = stride, padding = ks//2, bias = False),\n",
    "        nn.BatchNorm2d(out_),\n",
    "    ]\n",
    "    if activation: layers.append(nn.LeakyReLU())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(3,4,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class res_block(nn.Module):\n",
    "    def __init__(self,nb_filter):\n",
    "        \"\"\"\n",
    "        simple resnet block\n",
    "        \"\"\"\n",
    "        super(res_block,self).__init__()\n",
    "        self.nb_filter = nb_filter\n",
    "        self.clayer1 = conv_layer(self.nb_filter,self.nb_filter,3,(1,1))\n",
    "        self.clayer2 = conv_layer(self.nb_filter,self.nb_filter,3,(1,1),activation = False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x2 = self.clayer2(self.clayer1(x))\n",
    "        return x2+x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
