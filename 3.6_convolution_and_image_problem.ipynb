{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Image Classifcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going learn [food images](https://www.kaggle.com/kmader/food41) from kaggle\n",
    "\n",
    "### Use the kaggle-cli to download the image\n",
    "\n",
    "```kaggle datasets download -d kmader/food41```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME = os.environ[\"HOME\"]\n",
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace/.kaggle/datasets/kmader/food41/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA  = HOME+\"/.kaggle/datasets/kmader/food41/\"\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.3G\\t/home/paperspace/.kaggle/datasets/kmader/food41/food41.zip',\n",
       " '343M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_c101_n1000_r384x384x3.h5',\n",
       " '18M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_c101_n10099_r32x32x1.h5',\n",
       " '30M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_c101_n10099_r32x32x3.h5',\n",
       " '68M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_c101_n10099_r64x64x1.h5',\n",
       " '115M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_c101_n10099_r64x64x3.h5',\n",
       " '25M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_test_c101_n1000_r128x128x1.h5',\n",
       " '44M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_test_c101_n1000_r128x128x3.h5',\n",
       " '1.9M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_test_c101_n1000_r32x32x1.h5',\n",
       " '3.2M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_test_c101_n1000_r32x32x3.h5',\n",
       " '6.7M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_test_c101_n1000_r64x64x1.h5',\n",
       " '12M\\t/home/paperspace/.kaggle/datasets/kmader/food41/food_test_c101_n1000_r64x64x3.h5',\n",
       " '4.8G\\t/home/paperspace/.kaggle/datasets/kmader/food41/images.zip',\n",
       " '668K\\t/home/paperspace/.kaggle/datasets/kmader/food41/meta.zip']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!du -sh {DATA}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11240352\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 5681757245 Aug  2 01:45 \u001b[0m\u001b[01;31mfood41.zip\u001b[0m\r\n",
      "-rw-rw-r-- 1 paperspace paperspace  359407496 Aug  2 01:45 food_c101_n1000_r384x384x3.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   18236331 Aug  2 01:45 food_c101_n10099_r32x32x1.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   30452874 Aug  2 01:45 food_c101_n10099_r32x32x3.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   70546750 Aug  2 01:45 food_c101_n10099_r64x64x1.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace  120306214 Aug  2 01:45 food_c101_n10099_r64x64x3.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   26042428 Aug  2 01:45 food_test_c101_n1000_r128x128x1.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   45897229 Aug  2 01:45 food_test_c101_n1000_r128x128x3.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace    1938115 Aug  2 01:45 food_test_c101_n1000_r32x32x1.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace    3294763 Aug  2 01:45 food_test_c101_n1000_r32x32x3.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace    6968764 Aug  2 01:45 food_test_c101_n1000_r64x64x1.h5\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   11869967 Aug  2 01:45 food_test_c101_n1000_r64x64x3.h5\r\n",
      "drwxrwxr-x 2 paperspace paperspace       4096 Aug  2 11:08 \u001b[01;34mimages\u001b[0m/\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 5132666035 Aug  2 01:45 \u001b[01;31mimages.zip\u001b[0m\r\n",
      "drwxrwxr-x 2 paperspace paperspace       4096 Aug  2 11:04 \u001b[01;34mmeta\u001b[0m/\r\n",
      "-rw-rw-r-- 1 paperspace paperspace     682599 Aug  2 01:45 \u001b[01;31mmeta.zip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p {DATA}images\n",
    "%mkdir -p {DATA}meta\n",
    "%ls -l {DATA}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip and calculate the line of sub-folders: categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['102']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!cd {DATA}/images; unzip ../images.zip > unzip.log;rm -rf unzip.log; ls -l|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total 4140',\n",
       " '-rw-rw-r-- 1 paperspace paperspace    1184 Jul  9  2014 classes.txt',\n",
       " '-rw-rw-r-- 1 paperspace paperspace    1184 Sep 23  2013 labels.txt',\n",
       " '-rw-rw-r-- 1 paperspace paperspace  566868 Sep 23  2013 test.json',\n",
       " '-rw-rw-r-- 1 paperspace paperspace  489429 Sep 23  2013 test.txt',\n",
       " '-rw-rw-r-- 1 paperspace paperspace 1697751 Sep 21  2013 train.json',\n",
       " '-rw-rw-r-- 1 paperspace paperspace 1468812 Sep 21  2013 train.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!cd {DATA}/meta; unzip -q ../meta.zip; ls -l meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace/.kaggle/datasets/kmader/food41/meta/meta/'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "META = DATA + \"meta/meta/\"\n",
    "META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.json preview ====================\n",
      "{\"churros\": [\"churros/1004234\", \"churros/1013460\",\n",
      "classes.txt preview ====================\n",
      "apple_pie\n",
      "baby_back_ribs\n",
      "baklava\n",
      "beef_carpaccio\n",
      "be\n",
      "train.txt preview ====================\n",
      "apple_pie/1005649\n",
      "apple_pie/1014775\n",
      "apple_pie/1026\n",
      "test.json preview ====================\n",
      "{\"churros\": [\"churros/1061830\", \"churros/1064042\",\n",
      "test.txt preview ====================\n",
      "apple_pie/1011328\n",
      "apple_pie/101251\n",
      "apple_pie/10343\n",
      "labels.txt preview ====================\n",
      "Apple pie\n",
      "Baby back ribs\n",
      "Baklava\n",
      "Beef carpaccio\n",
      "Be\n"
     ]
    }
   ],
   "source": [
    "for m_file in os.listdir(META):\n",
    "    print(m_file, \"preview\",\"=\"*20)\n",
    "    print(open(META+m_file).read()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace/.kaggle/datasets/kmader/food41/images/'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG = DATA+\"images/\"\n",
    "IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_set = ImageFolder(IMG,transform = transform, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train /Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set = ImageFolder(IMG,transform = transform, )\n",
    "val_set = ImageFolder(IMG,transform = transform, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pick = np.random.rand(len(img_set.samples))>0.8\n",
    "trn_pick = ~val_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set.samples = np.array(img_set.samples)[trn_pick].tolist()\n",
    "val_set.samples = np.array(img_set.samples)[val_pick].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80504, 20496)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_set),len(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-1.1932, -1.1589, -1.1418,  ..., -1.4672, -1.4672, -1.3644],\n",
       "           [-1.5357, -1.5014, -1.4329,  ..., -1.5185, -1.6384, -1.6555],\n",
       "           [-1.4329, -1.4500, -1.4500,  ..., -1.4500, -1.4843, -1.6042],\n",
       "           ...,\n",
       "           [-1.2103, -1.2274, -1.2617,  ..., -1.3473, -1.3302, -1.3473],\n",
       "           [-1.1932, -1.0562, -0.9534,  ..., -1.3644, -1.3644, -1.3644],\n",
       "           [-1.0390, -0.9705, -0.9363,  ..., -1.3987, -1.3987, -1.4158]],\n",
       " \n",
       "          [[-1.0728, -1.0553, -1.0378,  ..., -1.3704, -1.3704, -1.2829],\n",
       "           [-1.2829, -1.2479, -1.2129,  ..., -1.3529, -1.4580, -1.4755],\n",
       "           [-1.1078, -1.1429, -1.1779,  ..., -1.2654, -1.2829, -1.4055],\n",
       "           ...,\n",
       "           [-0.9853, -1.0728, -1.1954,  ..., -1.3179, -1.3179, -1.3354],\n",
       "           [-0.9678, -0.9153, -0.9503,  ..., -1.3354, -1.3529, -1.3529],\n",
       "           [-0.8277, -0.8452, -0.9678,  ..., -1.3704, -1.3880, -1.4055]],\n",
       " \n",
       "          [[-1.0027, -0.9678, -0.9504,  ..., -1.2293, -1.2467, -1.1421],\n",
       "           [-1.1596, -1.1247, -1.0550,  ..., -1.2293, -1.3513, -1.3687],\n",
       "           [-0.9504, -0.9853, -0.9853,  ..., -1.1421, -1.1770, -1.3164],\n",
       "           ...,\n",
       "           [-0.9504, -1.0027, -1.1073,  ..., -1.1596, -1.1596, -1.1770],\n",
       "           [-1.1596, -1.0027, -0.8981,  ..., -1.1944, -1.1944, -1.1944],\n",
       "           [-1.1596, -1.0376, -0.9330,  ..., -1.2293, -1.2293, -1.2467]]]]),\n",
       " ('0',)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = iter(DataLoader(trn_set))\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_, out_, ks=3, activation = nn.ReLU()):\n",
    "    return nn.Sequential(*[\n",
    "        nn.Conv2d(in_, out_, kernel_size=ks, padding=ks//3, bias = False),\n",
    "        nn.BatchNorm2d(out_,),\n",
    "        activation,\n",
    "    ])\n",
    "\n",
    "def conv_block(in_,out_,nb_layers):\n",
    "    layers = []\n",
    "    for i in range(nb_layers):\n",
    "        if i == 0: layers.append(conv_layer(in_,out_))\n",
    "        elif i == nb_layers - 1:layers.append(conv_layer(out_,out_,activation = nn.MaxPool2d((2,2))))\n",
    "        else: layers.append(conv_layer(out_,out_))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.vgg = conv_block(3,32,2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
